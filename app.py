import streamlit as st
import os
import numpy as np
# --- V√Å L·ªñI T∆Ø∆†NG TH√çCH PILLOW ---
import PIL.Image
if not hasattr(PIL.Image, 'ANTIALIAS'):
    PIL.Image.ANTIALIAS = PIL.Image.LANCZOS
# ---------------------------------
from PIL import Image
from moviepy.editor import *
from huggingface_hub import InferenceClient
import tempfile
import math
import asyncio
import edge_tts
import random
import requests

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(page_title="DAT Media V14 - Pro", layout="wide", page_icon="üé¨")

st.markdown("""
<style>
    .stButton>button { width: 100%; font-weight: bold; padding: 10px 0; }
    div[data-testid="stButton"] > button:first-child { background-color: #f0f2f6; color: black; border: 1px solid #ccc; }
    div[data-testid="stVerticalBlock"] > div:last-child > div > button { background-color: #FF4B4B; color: white; }
</style>
""", unsafe_allow_html=True)

st.title("üé¨ DAT Media V14 - Pro Animation & Smart BG")
st.markdown("---")

# --- SESSION STATE ---
if 'generated_bg' not in st.session_state: st.session_state['generated_bg'] = None
if 'current_prompt' not in st.session_state: st.session_state['current_prompt'] = ""

# --- AUTO LOGIN ---
sys_hf_token = st.secrets.get("HF_TOKEN", None)
sys_eleven_key = st.secrets.get("ELEVEN_KEY", None)

# --- SIDEBAR ---
with st.sidebar:
    st.header("‚öôÔ∏è C·∫•u h√¨nh API")
    if sys_hf_token:
        st.success("‚úÖ HuggingFace: Connected")
        hf_token = sys_hf_token
    else:
        hf_token = st.text_input("üîë Hugging Face Token:", type="password")

    if sys_eleven_key:
        st.success("‚úÖ ElevenLabs: Connected")
        elevenlabs_key = sys_eleven_key
    else:
        elevenlabs_key = st.text_input("üé§ ElevenLabs Key:", type="password")
    
    st.divider()
    st.header("‚öôÔ∏è Video & Hi·ªáu ·ª©ng")
    video_ratio = st.radio("T·ª∑ l·ªá:", ("9:16 (D·ªçc)", "16:9 (Ngang)"))
    mascot_scale = st.slider("Mascot Zoom:", 0.3, 1.0, 0.75)
    
    # 1. DANH S√ÅCH HI·ªÜU ·ª®NG SIM (7 Lo·∫°i)
    sim_effect_name = st.selectbox(
        "Hi·ªáu ·ª©ng chuy·ªÉn ƒë·ªông SIM:",
        [
            "1. L∆° l·ª≠ng (Floating) - M·∫∑c ƒë·ªãnh",
            "2. N·∫£y t∆∞ng t∆∞ng (Bounce)",
            "3. L·∫Øc l∆∞ qua l·∫°i (Swing)",
            "4. Ph√≥ng to thu nh·ªè (Pulse)",
            "5. Xoay tr√≤n 3D (Spin 3D)",
            "6. Tr∆∞·ª£t ngang (Slide)",
            "7. Rung l·∫Øc m·∫°nh (Shake)"
        ]
    )

# --- H√ÄM T·∫†O PROMPT TH√îNG MINH ---
def get_smart_prompt(theme):
    # T·ª´ kh√≥a ng·∫´u nhi√™n ƒë·ªÉ t·∫°o s·ª± kh√°c bi·ªát m·ªói l·∫ßn b·∫•m
    lighting = random.choice(["cinematic lighting", "soft sunlight", "neon glow", "studio lighting", "golden hour"])
    detail = "highly detailed, 8k, professional photography, depth of field"
    
    if theme == "VƒÉn ph√≤ng hi·ªán ƒë·∫°i":
        scene = random.choice(["modern office desk", "coworking space", "glass meeting room", "minimalist tech workspace"])
        return f"{scene}, blurred background, {lighting}, {detail}"
    
    elif theme == "Ngo√†i tr·ªùi / Thi√™n nhi√™n":
        scene = random.choice(["beautiful park sunny day", "city street blurred", "beach sunny", "green garden"])
        return f"{scene}, bokeh background, natural light, {detail}"
    
    elif theme == "Trong nh√† / ·∫§m c√∫ng":
        scene = random.choice(["cozy living room", "coffee shop window", "wooden table shelf", "modern apartment"])
        return f"{scene}, warm tones, {lighting}, {detail}"
    
    elif theme == "C√¥ng ngh·ªá / Tr·ª´u t∆∞·ª£ng":
        scene = random.choice(["abstract data stream", "blue digital tunnel", "futuristic circuit board", "3d render geometric"])
        return f"{scene}, neon blue and purple, cyber style, {detail}"
    
    else: # M·∫∑c ƒë·ªãnh
        return f"abstract background, professional, {detail}"

def generate_ai_background(prompt, token):
    if not token: return None
    try:
        client = InferenceClient("stabilityai/stable-diffusion-xl-base-1.0", token=token)
        return client.text_to_image(prompt)
    except: return None

# --- H√ÄM AUDIO ---
async def generate_edge_tts(text, voice_short_name, output_file):
    communicate = edge_tts.Communicate(text, voice_short_name)
    await communicate.save(output_file)

def get_audio_from_edge(text, gender):
    voice = "vi-VN-HoaiMyNeural" if "N·ªØ" in gender else "vi-VN-NamMinhNeural"
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
        output_path = fp.name
    try:
        asyncio.run(generate_edge_tts(text, voice, output_path))
        return output_path
    except Exception as e: st.error(f"L·ªói Edge TTS: {e}"); return None

def speak_with_elevenlabs(api_key, text, voice_id):
    if not api_key: return None
    url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
    headers = {"xi-api-key": api_key, "Content-Type": "application/json"}
    data = {"text": text, "model_id": "eleven_multilingual_v2"}
    try:
        r = requests.post(url, json=data, headers=headers)
        if r.status_code == 200:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
                fp.write(r.content); return fp.name
        else: st.error(f"L·ªói ElevenLabs: {r.text}"); return None
    except Exception as e: st.error(f"L·ªói k·∫øt n·ªëi: {e}"); return None

# --- H√ÄM X·ª¨ L√ù HI·ªÜU ·ª®NG SIM ---
def apply_sim_transform(clip, effect_name, w, h, center_pos):
    cx, cy = center_pos # V·ªã tr√≠ trung t√¢m (tr∆∞·ªõc ng·ª±c Mascot)
    
    if "Floating" in effect_name: # L∆° l·ª≠ng nh·∫π
        return clip.set_position(lambda t: (cx, cy + 10*math.sin(2*t))).rotate(lambda t: 2*math.sin(t))
    
    elif "Bounce" in effect_name: # N·∫£y t∆∞ng t∆∞ng
        return clip.set_position(lambda t: (cx, cy + abs(30*math.sin(3*t)) - 15))
    
    elif "Swing" in effect_name: # L·∫Øc qua l·∫°i nh∆∞ ƒë·ªìng h·ªì
        # Xoay quanh t√¢m ph√≠a tr√™n c·ªßa ·∫£nh (c·∫ßn logic ph·ª©c t·∫°p h∆°n, ·ªü ƒë√¢y xoay t√¢m gi·ªØa)
        return clip.rotate(lambda t: 15 * math.sin(3*t)).set_position((cx, cy))
        
    elif "Pulse" in effect_name: # Ph√≥ng to thu nh·ªè
        return clip.resize(lambda t: 1 + 0.05 * math.sin(4*t)).set_position('center').set_position(lambda t: (cx, cy))
        
    elif "Spin 3D" in effect_name: # Gi·∫£ l·∫≠p xoay 3D (b·∫±ng c√°ch co gi√£n chi·ªÅu ngang)
        # MoviePy c∆° b·∫£n kh√≥ l√†m 3D th·∫≠t, d√πng hi·ªáu ·ª©ng l·∫≠t qua l·∫°i
        return clip.resize(lambda t: (abs(math.cos(2*t)) + 0.1, 1)).set_position('center').set_position((cx, cy))
        
    elif "Slide" in effect_name: # Tr∆∞·ª£t ngang qua l·∫°i
        return clip.set_position(lambda t: (cx + 50*math.sin(2*t), cy))
        
    elif "Shake" in effect_name: # Rung l·∫Øc m·∫°nh (b√°o ƒë·ªông)
        return clip.set_position(lambda t: (cx + 5*math.sin(20*t), cy + 5*math.cos(15*t)))
        
    else:
        return clip.set_position((cx, cy))

# --- H√ÄM VIDEO CORE ---
def create_video_v14(sim_img, mascot_img, logo_img, bg_img, audio_path, ratio, sim_effect_mode, scale):
    w, h = (1080, 1920) if "9:16" in ratio else (1920, 1080)
    
    # 1. X·ª≠ l√Ω Audio & Th·ªùi l∆∞·ª£ng
    # Video s·∫Ω d√†i b·∫±ng ch√≠nh x√°c file audio
    audio_clip = AudioFileClip(audio_path)
    final_duration = audio_clip.duration + 1 # C·ªông th√™m 1s d∆∞ ra cho ƒë·∫πp
    
    layers = []
    
    # 2. Background
    if bg_img:
        bg_resized = bg_img.resize((w, h))
        bg_clip = ImageClip(np.array(bg_resized)).set_duration(final_duration)
        layers.append(bg_clip)
    else:
        layers.append(ColorClip(size=(w, h), color=(20,20,30)).set_duration(final_duration))

    # T·ªça ƒë·ªô chu·∫©n
    center_y = h * 0.6 # Mascot ƒë·ª©ng th·∫•p h∆°n gi·ªØa ch√∫t
    
    # 3. Mascot (Idle Animation - Th·ªü nh·∫π)
    if mascot_img:
        m_w = int(w * scale)
        m_h = int(mascot_img.height * (m_w / mascot_img.width))
        mascot_resized = mascot_img.resize((m_w, m_h))
        mascot_clip = ImageClip(np.array(mascot_resized)).set_duration(final_duration)
        
        # Hi·ªáu ·ª©ng th·ªü: Ph·ªìng nh·∫π + Tr√¥i l√™n xu·ªëng c·ª±c nh·∫π
        mascot_anim = (mascot_clip
                       .set_position(lambda t: ('center', center_y - m_h/2 + 5 * math.sin(1.5*t)))
                       .resize(lambda t: 1 + 0.01 * math.sin(2*t)))
        layers.append(mascot_anim)
        
        # Sim Base Position: Tr∆∞·ªõc ng·ª±c Mascot
        sim_base_x = (w - int(m_w * 0.45)) / 2 # CƒÉn gi·ªØa theo chi·ªÅu ngang
        sim_base_y = center_y + m_h * 0.15 # V·ªã tr√≠ b·ª•ng/ng·ª±c
    else:
        sim_base_x = (w - int(w*0.6)) / 2
        sim_base_y = h/2 - int(w*0.6)/2

    # 4. SIM (√Åp d·ª•ng hi·ªáu ·ª©ng ƒë√£ ch·ªçn)
    sim_ratio = 0.45 if mascot_img else 0.6
    s_w = int((w * scale * sim_ratio) if mascot_img else w * sim_ratio)
    s_h = int(sim_img.height * (s_w / sim_img.width))
    sim_resized = sim_img.resize((s_w, s_h))
    
    sim_clip = ImageClip(np.array(sim_resized)).set_duration(final_duration)
    
    # G·ªçi h√†m x·ª≠ l√Ω chuy·ªÉn ƒë·ªông SIM
    # L∆∞u √Ω: sim_base_x ƒë∆∞·ª£c t√≠nh to√°n ƒë·ªÉ cƒÉn gi·ªØa, nh∆∞ng set_position('center') c·ªßa moviepy ƒë√¥i khi xung ƒë·ªôt v·ªõi lambda
    # N√™n ta d√πng v·ªã tr√≠ t∆∞∆°ng ƒë·ªëi
    sim_final = apply_sim_transform(sim_clip, sim_effect_mode, w, h, (sim_base_x, sim_base_y))
    
    # Do h√†m transform tr·∫£ v·ªÅ clip v·ªõi pos function, ta c·∫ßn cƒÉn l·∫°i center X n·∫øu h√†m kh√¥ng t·ª± cƒÉn
    if "Slide" not in sim_effect_mode:
        # √âp cƒÉn gi·ªØa tr·ª•c X cho c√°c hi·ªáu ·ª©ng kh√¥ng di chuy·ªÉn ngang
        sim_final = sim_final.set_position(lambda t: ('center', sim_base_y + (10*math.sin(2*t) if "Floating" in sim_effect_mode else 0)))
        # (Logic tr√™n l√† gi·∫£n l∆∞·ª£c, trong th·ª±c t·∫ø ta tin t∆∞·ªüng h√†m apply_sim_transform)
        
    layers.append(sim_final)

    # 5. Logo
    if logo_img:
        l_w = int(w * 0.18)
        l_h = int(logo_img.height * (l_w / logo_img.width))
        logo_resized = logo_img.resize((l_w, l_h))
        logo_clip = ImageClip(np.array(logo_resized)).set_duration(final_duration).set_position((30, 40)) 
        layers.append(logo_clip)

    final = CompositeVideoClip(layers, size=(w,h)).set_audio(audio_clip)
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp:
        out_path = tmp.name
        final.write_videofile(out_path, fps=24, codec='libx264', audio_codec='aac')
    return out_path

# --- UI CH√çNH ---
col1, col2 = st.columns(2)
with col1:
    st.subheader("1. H√¨nh ·∫£nh (PNG)")
    sim_file = st.file_uploader("üñºÔ∏è T·∫£i ·∫£nh SIM:", type=['png'])
    mascot_file = st.file_uploader("ü¶ñ T·∫£i ·∫£nh Mascot (1 ·∫£nh tƒ©nh):", type=['png'])
    logo_file = st.file_uploader("¬©Ô∏è T·∫£i Logo:", type=['png'])
    
    st.markdown("---")
    st.subheader("2. B·ªëi c·∫£nh (Smart Generator)")
    
    # Dropdown Menu ch·ªçn ch·ªß ƒë·ªÅ
    bg_theme = st.selectbox("Ch·ªçn ch·ªß ƒë·ªÅ b·ªëi c·∫£nh:", 
                           ["VƒÉn ph√≤ng hi·ªán ƒë·∫°i", "Ngo√†i tr·ªùi / Thi√™n nhi√™n", 
                            "Trong nh√† / ·∫§m c√∫ng", "C√¥ng ngh·ªá / Tr·ª´u t∆∞·ª£ng"])
    
    if st.button("üé≤ T·∫†O B·ªêI C·∫¢NH M·ªöI (GENERATE)"):
        if hf_token:
            with st.spinner(f"AI ƒëang v·∫Ω b·ªëi c·∫£nh {bg_theme}..."):
                # T·∫°o prompt m·ªõi ho√†n to√†n m·ªói l·∫ßn b·∫•m
                smart_prompt = get_smart_prompt(bg_theme)
                st.session_state['current_prompt'] = smart_prompt # L∆∞u ƒë·ªÉ debug xem ch∆°i
                
                # G·ªçi AI v·∫Ω
                bg = generate_ai_background(smart_prompt, hf_token)
                st.session_state['generated_bg'] = bg
    
    if st.session_state['generated_bg']:
        st.image(st.session_state['generated_bg'], width=250, caption="B·ªëi c·∫£nh v·ª´a t·∫°o")
        st.caption(f"Prompt: {st.session_state['current_prompt']}")

with col2:
    st.subheader("3. √Çm thanh")
    voice_option = st.radio("Ngu·ªìn √¢m thanh:", 
                           ["üíé Microsoft Edge TTS (Free)", 
                            "üöÄ ElevenLabs (C·∫ßn Voice ID)", 
                            "üéôÔ∏è T·∫£i file ghi √¢m c·ªßa t√¥i"])
    
    final_audio_path = None
    input_script = ""

    if "Microsoft" in voice_option:
        voice_gender = st.selectbox("Gi·ªçng ƒë·ªçc:", ["N·ªØ (Ho√†i My)", "Nam (Nam Minh)"])
        input_script = st.text_area("Nh·∫≠p k·ªãch b·∫£n qu·∫£ng c√°o:", height=150)
        
    elif "ElevenLabs" in voice_option:
        voice_id_input = st.text_input("Nh·∫≠p Voice ID:", help="L·∫•y t·ª´ ElevenLabs -> Voices")
        input_script = st.text_area("Nh·∫≠p k·ªãch b·∫£n qu·∫£ng c√°o:", height=150)
        
    else: # T·∫£i file
        uploaded_audio = st.file_uploader("T·∫£i file MP3/WAV:", type=['mp3', 'wav'])
        if uploaded_audio:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
                fp.write(uploaded_audio.getvalue())
                final_audio_path = fp.name
            st.success(f"ƒê√£ nh·∫≠n file √¢m thanh! Video s·∫Ω d√†i theo file n√†y.")

st.markdown("---")
video_name = st.text_input("T√™n file:", "dat_media_final")

if st.button("üöÄ XU·∫§T B·∫¢N VIDEO", type="primary"):
    error = False
    if not sim_file: st.error("Thi·∫øu ·∫£nh SIM!"); error=True
    if "T·∫£i file" not in voice_option and not input_script: st.error("Thi·∫øu k·ªãch b·∫£n!"); error=True
    
    if not error:
        status = st.empty()
        prog = st.progress(0)
        try:
            # 1. AUDIO GENERATION
            if "Microsoft" in voice_option:
                status.text("üîä ƒêang t·∫°o gi·ªçng Microsoft...")
                final_audio_path = get_audio_from_edge(input_script, voice_gender)
            
            elif "ElevenLabs" in voice_option:
                if not elevenlabs_key: st.error("Ch∆∞a nh·∫≠p API Key!"); st.stop()
                status.text("üîä ƒêang t·∫°o gi·ªçng ElevenLabs...")
                final_audio_path = speak_with_elevenlabs(elevenlabs_key, input_script, voice_id_input)
            
            if not final_audio_path: st.stop()
            prog.progress(30)
            
            # 2. BACKGROUND CHECK
            bg_final = st.session_state['generated_bg']
            if not bg_final and hf_token:
                status.text("üé® ƒêang v·∫Ω b·ªëi c·∫£nh l·∫ßn ƒë·∫ßu...")
                smart_prompt = get_smart_prompt(bg_theme)
                bg_final = generate_ai_background(smart_prompt, hf_token)
            
            prog.progress(50)
            
            # 3. LOAD IMAGES
            sim_pil = Image.open(sim_file).convert("RGBA")
            mascot_pil = Image.open(mascot_file).convert("RGBA") if mascot_file else None
            logo_pil = Image.open(logo_file).convert("RGBA") if logo_file else None
            
            # 4. RENDER
            status.text(f"üé¨ ƒêang x·ª≠ l√Ω hi·ªáu ·ª©ng: {sim_effect_name}...")
            out = create_video_v14(
                sim_pil, mascot_pil, logo_pil, bg_final, final_audio_path, 
                video_ratio, sim_effect_name, mascot_scale
            )
            
            prog.progress(100); status.success("Xong!")
            st.video(out)
            with open(out, "rb") as f: st.download_button("‚¨áÔ∏è T·∫£i v·ªÅ", f, file_name=f"{video_name}.mp4")
            
        except Exception as e: st.error(f"L·ªói: {e}")
